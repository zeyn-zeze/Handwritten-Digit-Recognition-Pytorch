# -*- coding: utf-8 -*-
"""Untitled1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1eBaDX5BYeRb9AATELZo47AiYD_VWZ-Ae

# Handwritten Digit Recognition
"""

from timeit import default_timer as timer
import os

import numpy as np
import matplotlib.pyplot as plt

import torch
from torch import nn
import torchvision
from torchvision import datasets, transforms

#device's agnostic code
device = "cuda" if torch.cuda.is_available() else "cpu"

"""## 1. Transform Image to Tensor Format"""

transform = transforms.Compose([transforms.ToTensor(),
                                transforms.Normalize((0.1307,), (0.3081,))])

"""## 2. Downloading Train and Test Data"""

trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)
testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)

"""## 3. Load Batch_size with DataLoader"""

train_loader = torch.utils.data.DataLoader(trainset,batch_size=64,shuffle=True)
test_loader= torch.utils.data.DataLoader(testset,batch_size=64,shuffle=False)

"""##4. Data Visualizing and Exploring"""

data_counter = iter(train_loader)
images, labels = next(data_counter)

print(images.shape)
print(labels.shape)

# plot the first value
plt.imshow(images[0].numpy().squeeze(), cmap='gray_r');

#Shows 15 data within 3 rows and 5 column
num_images = 15
rows, cols = 3, 5

fig, axes = plt.subplots(rows, cols, figsize=(10, 6))
fig.tight_layout()

for i in range(num_images):
    row = i // cols   # row no
    col = i % cols    # col no

    ax = axes[row, col]
    ax.imshow(images[i].numpy().squeeze(), cmap="gray") # plot each img
    ax.set_title(f"Label: {labels[i].item()}", fontsize=8)  # Write label name
    ax.axis("off")

"""## 5. Defining Model and Class"""

class MNISTModel(nn.Module):
    def __init__(self):
        super(MNISTModel,self).__init__()

        self.features = nn.Sequential(
            nn.Conv2d(1, 32, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2,2),
            nn.Conv2d(32, 64, 3, padding=1),
            nn.ReLU(),
            nn.MaxPool2d(2,2)
        )

        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Linear(64*7*7, 128),
            nn.ReLU(),
            nn.Dropout(0.3),
            nn.Linear(128, 10)
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x


model_mnist = MNISTModel()
model_mnist.to(device)
model_mnist

"""Setup loss and optimizer and evaluation metrics"""

import requests
from pathlib import Path

# download helper_function doc from pytorch learn repo
if Path("helper_functions.py").is_file():
  print("helper_functions.py already exists")
else:
  print("Downloading helper_functions.py")
  request = requests.get("https://raw.githubusercontent.com/mrdbourke/pytorch-deep-learning/main/helper_functions.py")
  with open("helper_functions.py","wb") as f:
    f.write(request.content)

"""## 6. Create loss function and optimizer

"""

from  helper_functions import accuracy_fn
# setup loss and optimizer
loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(params=model_mnist.parameters(), lr=0.001)

"""## 7. Creating function to time our experiment"""

def print_time(start:float,
               end : float,
               device:torch.device=None):
  total_time = end - start
  print(f"Time taken: {total_time:.3f} seconds")
  return total_time

"""## 8. Create training loop and training model"""

from tqdm.auto import tqdm
import torch
from timeit import default_timer as timer

torch.manual_seed(42)
# --- train_step ---
def train_step(model: torch.nn.Module,
               data_loader: torch.utils.data.DataLoader,
               loss_fn: torch.nn.Module,
               optimizer: torch.optim.Optimizer,
               accuracy_fn,
               device: torch.device):

  ### -- Training--

    model.train()
    train_loss, train_acc = 0, 0

    for X, y in data_loader:
        X, y = X.to(device), y.to(device)

        # Forward pass
        y_pred = model(X)

        # Loss & accuracy
        loss = loss_fn(y_pred, y)
        train_loss += loss.item()
        train_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))

        # Backward & optimize
        optimizer.zero_grad()
        loss.backward()
        optimizer.step()

    train_loss /= len(data_loader)
    train_acc /= len(data_loader)
    print(f"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%")
    return train_loss, train_acc

# --- test_step ---

def test_step(model: torch.nn.Module,
              data_loader: torch.utils.data.DataLoader,
              loss_fn: torch.nn.Module,
              accuracy_fn,
              device: torch.device):

    model.eval()
    test_loss, test_acc = 0, 0

    with torch.inference_mode():
        for X, y in data_loader:
            X, y = X.to(device), y.to(device)
            y_pred = model(X)

            test_loss += loss_fn(y_pred, y).item()
            test_acc += accuracy_fn(y_true=y, y_pred=y_pred.argmax(dim=1))

    test_loss /= len(data_loader)
    test_acc /= len(data_loader)
    print(f"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\n")
    return test_loss, test_acc

# --- Full epoch loop ---

epochs = 3
train_time_start_on_cpu = timer()

for epoch in tqdm(range(epochs), desc="Epochs"):
    print(f"\nEpoch {epoch+1}/{epochs}\n{'-'*20}")
    train_step(model_mnist, train_loader, loss_fn, optimizer, accuracy_fn, device)
    test_step(model_mnist, test_loader, loss_fn, accuracy_fn, device)

train_time_end_on_cpu = timer()
print(f"Total training time: {train_time_end_on_cpu - train_time_start_on_cpu:.2f} seconds")

"""## 9. Confussion Matrix

"""


import torch
import matplotlib.pyplot as plt
import seaborn as sns
from torchmetrics.classification import ConfusionMatrix

def plot_confusion_matrix(model, data_loader, device, split_name="Test"):
    model.eval()

    # labels
    all_labels = []
    # predicts
    all_preds = []

    with torch.inference_mode():
        for X, y in data_loader:
            X, y = X.to(device), y.to(device)
            preds = model(X).argmax(dim=1)

            all_labels.append(y)
            all_preds.append(preds)

    all_labels = torch.cat(all_labels)
    all_preds = torch.cat(all_preds)

    # Confusion matrix
    num_classes = 10
    cm_metric = ConfusionMatrix(task="multiclass", num_classes=num_classes).to(device)
    cm = cm_metric(all_preds, all_labels)  # preds, targets
    cm = cm.cpu().numpy()

    # Visualize
    plt.figure(figsize=(10,8))
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
    plt.xlabel("Predicted Labels")
    plt.ylabel("True Labels")
    plt.title(f"Confusion Matrix ({split_name} set)")
    plt.show()



plot_confusion_matrix(model_mnist, train_loader, device, split_name="Train")
plot_confusion_matrix(model_mnist, test_loader, device, split_name="Test")

